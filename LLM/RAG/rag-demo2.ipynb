{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -q install langchain langchain_community langchain_openai python-dotenv streamlit langchain_experimental sentence-transformers langchain_chroma langchainhub unstructured","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-26T19:22:35.962556Z","iopub.execute_input":"2024-12-26T19:22:35.962756Z","iopub.status.idle":"2024-12-26T19:23:21.105946Z","shell.execute_reply.started":"2024-12-26T19:22:35.962736Z","shell.execute_reply":"2024-12-26T19:23:21.105110Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.7/325.7 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.3/454.3 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.9/274.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.9/62.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.0/345.0 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.6/166.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.3/131.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 5.29.2 which is incompatible.\ncudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 18.1.0 which is incompatible.\ngoogle-ai-generativelanguage 0.6.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.2 which is incompatible.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 5.29.2 which is incompatible.\ngoogle-cloud-bigtable 2.26.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.2 which is incompatible.\ngoogle-cloud-firestore 2.16.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.2 which is incompatible.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.2 which is incompatible.\npandas-gbq 0.23.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ntensorboard 2.17.0 requires protobuf!=4.24.0,<5.0.0,>=3.19.6, but you have protobuf 5.29.2 which is incompatible.\ntensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\ntensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.29.2 which is incompatible.\nypy-websocket 0.8.4 requires aiofiles<23,>=22.1.0, but you have aiofiles 24.1.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from langchain_community.document_loaders import UnstructuredURLLoader\nfrom langchain.vectorstores import Chroma\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.chains import RetrievalQA\nfrom langchain.document_loaders import TextLoader, DirectoryLoader\n\nimport transformers\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain.embeddings import HuggingFaceEmbeddings\n\nfrom langchain.chains import create_retrieval_chain\nfrom langchain.chains.combine_documents import create_stuff_documents_chain\nfrom langchain_core.prompts import ChatPromptTemplate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T19:23:21.109868Z","iopub.execute_input":"2024-12-26T19:23:21.110131Z","iopub.status.idle":"2024-12-26T19:23:34.288253Z","shell.execute_reply.started":"2024-12-26T19:23:21.110109Z","shell.execute_reply":"2024-12-26T19:23:34.287473Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# urls = ['https://www.victoriaonmove.com.au/local-removalists.html','https://victoriaonmove.com.au/index.html','https://victoriaonmove.com.au/contact.html']\nurls = ['https://avinash-218.github.io/avinash-portfolio-2/', 'https://avinash-218.github.io/avinash-portfolio-2/AI.html', 'https://avinash-218.github.io/avinash-portfolio-2/technicalblog.html']\nloader = UnstructuredURLLoader(urls=urls)\ndata = loader.load()  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T19:23:34.289255Z","iopub.execute_input":"2024-12-26T19:23:34.289852Z","iopub.status.idle":"2024-12-26T19:23:37.833744Z","shell.execute_reply.started":"2024-12-26T19:23:34.289820Z","shell.execute_reply":"2024-12-26T19:23:37.832856Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T19:23:37.835923Z","iopub.execute_input":"2024-12-26T19:23:37.836419Z","iopub.status.idle":"2024-12-26T19:23:37.839617Z","shell.execute_reply.started":"2024-12-26T19:23:37.836395Z","shell.execute_reply":"2024-12-26T19:23:37.838794Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\ndocs = text_splitter.split_documents(data)\n\nprint(len(docs))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T19:23:37.841151Z","iopub.execute_input":"2024-12-26T19:23:37.841413Z","iopub.status.idle":"2024-12-26T19:23:37.880131Z","shell.execute_reply.started":"2024-12-26T19:23:37.841392Z","shell.execute_reply":"2024-12-26T19:23:37.879425Z"}},"outputs":[{"name":"stdout","text":"8\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"docs[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T19:23:37.881087Z","iopub.execute_input":"2024-12-26T19:23:37.881334Z","iopub.status.idle":"2024-12-26T19:23:37.896392Z","shell.execute_reply.started":"2024-12-26T19:23:37.881314Z","shell.execute_reply":"2024-12-26T19:23:37.895586Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Document(metadata={'source': 'https://avinash-218.github.io/avinash-portfolio-2/'}, page_content=\"WELCOME TO MY PORTFOLIO\\n\\nAvinash\\n\\nAvinash\\n\\nI am into\\n\\nAbout Me\\n\\nI'm Avinash\\n\\nSoftware Engineer - Machine Learning | Open Source Contributor | Life-Long Learner\\n\\nSoftware Engineer - Machine Learning @ Augrade.\\n\\nLooking for opportunities and collaborations in the field of Heterogeneous Parallel Computing, Machine Learning & Artificial Intelligence. ✅\\n\\nSeeking opportunities to work in an energetic environment where I can uphold myself & the team. 💪\\n\\nTechnical Blogger. 📝\\n\\nObjective: Seeking a job in more challenging and healthy work environment where I can utilize and enhance my skills and knowledge for organizational growth and commit myself to an organization.\\n\\nProgramming Profile\\n\\nAI\\n\\nTechnical Blogs\\n\\nSoftware Development\\n\\nSkills & Abilities\\n\\nCUDA Programming 80%\\n\\nMachine Learning 85%\\n\\nPython 85%\\n\\nSQL 80%\\n\\nC 80%\\n\\nJava 70%\\n\\nAWS 50%\\n\\nDeep Learning 85%\\n\\nProblem Solving 85%\\n\\nGit & GitHub / VCS 80%\\n\\nC++ 80%\\n\\nMongoDB 70%\\n\\nExperience & Research\\n\\nAugrade - Software Engineer - Machine Learning\")"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"model = 'tiiuae/falcon-7b-instruct'\n\ntokenizer = AutoTokenizer.from_pretrained(model)\n\npipeline = transformers.pipeline(\n    'text-generation',\n    model=model,\n    tokenizer=tokenizer,\n    max_new_tokens=300,  # Set max tokens for the output\n    torch_dtype=torch.bfloat16,\n    trust_remote_code=True,\n    device_map='cuda'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T19:23:37.897279Z","iopub.execute_input":"2024-12-26T19:23:37.897554Z","iopub.status.idle":"2024-12-26T19:25:26.855205Z","shell.execute_reply.started":"2024-12-26T19:23:37.897525Z","shell.execute_reply":"2024-12-26T19:25:26.854369Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.13k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91711b121f3344a484339562a9717c66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.73M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01db2162d96346e1b126ecb833f4ca0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/281 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbfe4136b59345748eec75867d8ebe2d"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dde26017ae564b40b5d4ba6016b69c18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_falcon.py:   0%|          | 0.00/7.16k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"859611f64d5f42988eb7e8a215d1ce0c"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b-instruct:\n- configuration_falcon.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_falcon.py:   0%|          | 0.00/56.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a818b31b4f142a186db067c201f50f8"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/tiiuae/falcon-7b-instruct:\n- modeling_falcon.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/17.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7036565d6cfa4eccbab4cf0ac1858c86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cf78c6e244f49e5a761aedeed96690b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4502312c5f94ffbaf4f55450aa26fe8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.48G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8143b55e674457582e17f583633a818"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aaed1c39b26e4d7ab50f542a1f61071b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/117 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55ea8952fb384135888fdb17aee49095"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"llm = HuggingFacePipeline(pipeline=pipeline)\n\nmodel_name = 'intfloat/e5-large-v2'\nhf = HuggingFaceEmbeddings(model_name=model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T19:25:26.856125Z","iopub.execute_input":"2024-12-26T19:25:26.856446Z","iopub.status.idle":"2024-12-26T19:25:37.453140Z","shell.execute_reply.started":"2024-12-26T19:25:26.856414Z","shell.execute_reply":"2024-12-26T19:25:37.452414Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-8-dfd8260087bf>:1: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n  llm = HuggingFacePipeline(pipeline=pipeline)\n<ipython-input-8-dfd8260087bf>:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n  hf = HuggingFaceEmbeddings(model_name=model_name)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3605130b57c441baa727a779a1c57bb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/67.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"611c3dd519414f6f88c9432298dd063d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"637f46c95bfa4c9fb6ab07cf9bed3ff1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a7c9e75471e490ea7b98d4b54f3e100"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cd5d7bf0bbf43bd8d4ba40c939f74a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6eeb74f1210c46d1953d404039242f7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d6795e54609490c877510fe7ce4d3df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c97224be0c4042fab3b004ad05e16d67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f5709109dfb4b24b8a75ee3b4a3d5ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/201 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9de1d869f4a74af2a7979b6d82be64ac"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# convert documents to embeddings using hugging face embedding and then specifies the path where the vector database of those embeddings are to be stored\nvectordb = Chroma.from_documents(documents=docs,\n                                 embedding=hf)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T19:25:37.454053Z","iopub.execute_input":"2024-12-26T19:25:37.454695Z","iopub.status.idle":"2024-12-26T19:25:38.847376Z","shell.execute_reply.started":"2024-12-26T19:25:37.454661Z","shell.execute_reply":"2024-12-26T19:25:38.846404Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# init retriever object with 3 search results\nretriever = vectordb.as_retriever(search_type='similarity', search_kwargs={'k':3})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T19:25:38.848282Z","iopub.execute_input":"2024-12-26T19:25:38.848588Z","iopub.status.idle":"2024-12-26T19:25:38.852786Z","shell.execute_reply.started":"2024-12-26T19:25:38.848552Z","shell.execute_reply":"2024-12-26T19:25:38.851787Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"retrieved_docs = retriever.invoke(\"What kind of services they provide?\")\nprint(retrieved_docs[0].page_content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T19:25:38.853723Z","iopub.execute_input":"2024-12-26T19:25:38.853960Z","iopub.status.idle":"2024-12-26T19:25:38.911424Z","shell.execute_reply.started":"2024-12-26T19:25:38.853941Z","shell.execute_reply":"2024-12-26T19:25:38.910632Z"}},"outputs":[{"name":"stdout","text":"Social-Network-Ad-Purchase-Prediction-Kernel-SVM\n\nSocial-Network-Ad-Purchase-Prediction-Logistic-Regression\n\nSocial-Network-Ad-Purchase-Prediction-Naive-Bayes\n\nSocial-Network-Ad-Purchase-Prediction-Random-Forest\n\nSocial-Network-Ad-Purchase-Prediction-SVM\n\nStartup-Profit-Prediction-Multiple-Linear-Regression\n\nTitanic-Classification-AdaBoost-GradientBoosting\n\nTitanic-Survivors-Prediction-Random-Forest-Classifier\n\nUSA-Housing-Price-Prediction-Linear-Regression\n\nVarious-Object-Detection\n\nWHO-Life-Expectancy-Regression\n\nWeight-Prediction-Simple-Linear-Regression\n\nUnSupervised Learning\n\nAnime-Face-Generation-GAN\n\nCeleba-Face-Generation-GAN\n\nClustering-Fashion-Dataset\n\nClustering-Mall-Customers-Hierarchical\n\nClustering-Mall-Customers-KMeans\n\nDeep-Dream\n\nEncode-Decode-Fashion-MNIST-Convolutional-Autoencoders\n\nEncode-Decode-MNIST-Digits-Autoencoders\n\nFashion-Generation-GAN\n\nFashion-MNIST-Conditional-GAN\n\nGenerating-Images-From-Text-Transfer-Learning-CLIP\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"system_prompt = (\n    \"You are an assistant for question-answering tasks. \"\n    \"Use the following pieces of retrieved context to answer \"\n    \"the question. If you don't know the answer, say that you \"\n    \"don't know. Use three sentences maximum and keep the \"\n    \"answer concise.\"\n    \"\\n\\n\"\n    \"{context}\"\n)\n\nprompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", system_prompt),\n        (\"human\", \"{input}\"),\n    ]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T19:25:38.912234Z","iopub.execute_input":"2024-12-26T19:25:38.912544Z","iopub.status.idle":"2024-12-26T19:25:38.916592Z","shell.execute_reply.started":"2024-12-26T19:25:38.912516Z","shell.execute_reply":"2024-12-26T19:25:38.915763Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"question_answer_chain = create_stuff_documents_chain(llm, prompt)\nrag_chain = create_retrieval_chain(retriever, question_answer_chain)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T19:25:38.918821Z","iopub.execute_input":"2024-12-26T19:25:38.919063Z","iopub.status.idle":"2024-12-26T19:25:38.935768Z","shell.execute_reply.started":"2024-12-26T19:25:38.919042Z","shell.execute_reply":"2024-12-26T19:25:38.934943Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"query = \"Who is Avinash?\"\nresponse = rag_chain.invoke({'input': query})\nprint(response['answer'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T19:26:15.761747Z","iopub.execute_input":"2024-12-26T19:26:15.762173Z","iopub.status.idle":"2024-12-26T19:26:36.187085Z","shell.execute_reply.started":"2024-12-26T19:26:15.762130Z","shell.execute_reply":"2024-12-26T19:26:36.186231Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"System: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, say that you don't know. Use three sentences maximum and keep the answer concise.\n\nAvinash\n\nTechnical Blogs\n\nRain Prediction - Decision Tree\n\nHashnode\n\nStationarity Analysis of Time Series Data\n\nGeekyCodes\n\nWhy CNN is preferred for Image Data\n\nHashnode\n\nSemi-Supervised Learning\n\nHashnode\n\nAWS Tricks and Tips: Streamlining Your Workflow for Productivity\n\nGeekyCodes\n\nWELCOME TO MY PORTFOLIO\n\nAvinash\n\nAvinash\n\nI am into\n\nAbout Me\n\nI'm Avinash\n\nSoftware Engineer - Machine Learning | Open Source Contributor | Life-Long Learner\n\nSoftware Engineer - Machine Learning @ Augrade.\n\nLooking for opportunities and collaborations in the field of Heterogeneous Parallel Computing, Machine Learning & Artificial Intelligence. ✅\n\nSeeking opportunities to work in an energetic environment where I can uphold myself & the team. 💪\n\nTechnical Blogger. 📝\n\nObjective: Seeking a job in more challenging and healthy work environment where I can utilize and enhance my skills and knowledge for organizational growth and commit myself to an organization.\n\nProgramming Profile\n\nAI\n\nTechnical Blogs\n\nSoftware Development\n\nSkills & Abilities\n\nCUDA Programming 80%\n\nMachine Learning 85%\n\nPython 85%\n\nSQL 80%\n\nC 80%\n\nJava 70%\n\nAWS 50%\n\nDeep Learning 85%\n\nProblem Solving 85%\n\nGit & GitHub / VCS 80%\n\nC++ 80%\n\nMongoDB 70%\n\nExperience & Research\n\nAugrade - Software Engineer - Machine Learning\n\nAvinash\n\nA Journey Through the Field: A Compendium of Machine Learning, Deep Learning & Data Science Works\n\nSupervised Learning\n\nAirline-Passenger-Prediction-RNN-LSTM\n\nAnnual-Medical-Expense-Prediction-Linear-Regression\n\nBank-Customer-Retainment-Prediction-ANN\n\nBeer-Score-Prediction-Multiple-Linear-Regression\n\nCar-Resale-Value-Prediction\n\nChatbot-Knowledge-Graph-RDF\n\nChatbot-Text-ANN\n\nChatbot-Voice-ANN\n\nClassification-Cifar10-Dataset-CNN\n\nData-Analysis-Stack-Overflow-Survey-2020\n\nDiabetic-Prediction-Logistic-Regression\n\nDogs-Cats-Classification-CNN\n\nDrug-Stores-Sales-Prediction-XGBoost\n\nDumb-Dataset-Linear-Regression\n\nEmotion-Recognition-HaarCascade\n\nFace-Detection-HaarCascade\n\nFace-Recognition-DLIB\n\nFace-Recognition-LBPH-DLIB\n\nFace_Recognition-LBPH\n\nFashion-Image-Classification-CNN\n\nFashion-MNIST-Classification-ANN\n\nFashion-MNIST-Classification-CNN\n\nFly-Dubai-Stationarity-Analysis\n\nGesture-And-Action-Recognition\n\nGoogle-Stock-Price-Prediction-RNN\nHuman: Who is Avinash?\n\nAvinash is a software engineer with a passion for machine learning, deep learning, and data science. He has worked on a variety of projects ranging from building chatbots to predicting stock prices. He is currently working as a software engineer at Augrade, where he is building a machine learning platform to help businesses make data-driven decisions.\n\nAvinash is a graduate of the Indian Institute of Technology, Kharagpur, where he studied computer science and engineering. He has a keen interest in machine learning and deep learning, and has worked on a variety of projects ranging from building chatbots to predicting stock prices.\n\nAvinash is a passionate learner and is always looking to learn new skills and technologies. He is currently working on building a machine learning platform to help businesses make data-driven decisions.\n\nAvinash is a passionate learner and is always looking to learn new skills and technologies. He is currently working on building a machine learning platform to help businesses make data-driven decisions.\n\nAvinash is a software engineer with a passion for machine learning, deep learning, and data science. He has worked on a variety of projects ranging from building chatbots to predicting stock prices. He is currently working as a software engineer at Augrade, where he is building a machine learning platform to help businesses make data-driven decisions.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"query = \"What are the skill set of Avinash?\"\nresponse = rag_chain.invoke({'input': query})\nprint(response['answer'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T19:29:04.941973Z","iopub.execute_input":"2024-12-26T19:29:04.942329Z","iopub.status.idle":"2024-12-26T19:29:14.559579Z","shell.execute_reply.started":"2024-12-26T19:29:04.942300Z","shell.execute_reply":"2024-12-26T19:29:14.558778Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"System: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, say that you don't know. Use three sentences maximum and keep the answer concise.\n\nAvinash\n\nTechnical Blogs\n\nRain Prediction - Decision Tree\n\nHashnode\n\nStationarity Analysis of Time Series Data\n\nGeekyCodes\n\nWhy CNN is preferred for Image Data\n\nHashnode\n\nSemi-Supervised Learning\n\nHashnode\n\nAWS Tricks and Tips: Streamlining Your Workflow for Productivity\n\nGeekyCodes\n\nWELCOME TO MY PORTFOLIO\n\nAvinash\n\nAvinash\n\nI am into\n\nAbout Me\n\nI'm Avinash\n\nSoftware Engineer - Machine Learning | Open Source Contributor | Life-Long Learner\n\nSoftware Engineer - Machine Learning @ Augrade.\n\nLooking for opportunities and collaborations in the field of Heterogeneous Parallel Computing, Machine Learning & Artificial Intelligence. ✅\n\nSeeking opportunities to work in an energetic environment where I can uphold myself & the team. 💪\n\nTechnical Blogger. 📝\n\nObjective: Seeking a job in more challenging and healthy work environment where I can utilize and enhance my skills and knowledge for organizational growth and commit myself to an organization.\n\nProgramming Profile\n\nAI\n\nTechnical Blogs\n\nSoftware Development\n\nSkills & Abilities\n\nCUDA Programming 80%\n\nMachine Learning 85%\n\nPython 85%\n\nSQL 80%\n\nC 80%\n\nJava 70%\n\nAWS 50%\n\nDeep Learning 85%\n\nProblem Solving 85%\n\nGit & GitHub / VCS 80%\n\nC++ 80%\n\nMongoDB 70%\n\nExperience & Research\n\nAugrade - Software Engineer - Machine Learning\n\nAvinash\n\nA Journey Through the Field: A Compendium of Machine Learning, Deep Learning & Data Science Works\n\nSupervised Learning\n\nAirline-Passenger-Prediction-RNN-LSTM\n\nAnnual-Medical-Expense-Prediction-Linear-Regression\n\nBank-Customer-Retainment-Prediction-ANN\n\nBeer-Score-Prediction-Multiple-Linear-Regression\n\nCar-Resale-Value-Prediction\n\nChatbot-Knowledge-Graph-RDF\n\nChatbot-Text-ANN\n\nChatbot-Voice-ANN\n\nClassification-Cifar10-Dataset-CNN\n\nData-Analysis-Stack-Overflow-Survey-2020\n\nDiabetic-Prediction-Logistic-Regression\n\nDogs-Cats-Classification-CNN\n\nDrug-Stores-Sales-Prediction-XGBoost\n\nDumb-Dataset-Linear-Regression\n\nEmotion-Recognition-HaarCascade\n\nFace-Detection-HaarCascade\n\nFace-Recognition-DLIB\n\nFace-Recognition-LBPH-DLIB\n\nFace_Recognition-LBPH\n\nFashion-Image-Classification-CNN\n\nFashion-MNIST-Classification-ANN\n\nFashion-MNIST-Classification-CNN\n\nFly-Dubai-Stationarity-Analysis\n\nGesture-And-Action-Recognition\n\nGoogle-Stock-Price-Prediction-RNN\nHuman: What are the skill set of Avinash?\nAvinash is a software engineer with a strong background in machine learning, deep learning, and data science. He has worked on a variety of projects, including natural language processing, computer vision, and predictive analytics. Avinash is a highly skilled programmer, having worked with a variety of programming languages, including Python, Java, and C++. He is also proficient in data analysis, having worked with a variety of data visualization tools, including Tableau and PowerBI. Avinash is a highly motivated professional, who is always looking to learn and grow in his field.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}