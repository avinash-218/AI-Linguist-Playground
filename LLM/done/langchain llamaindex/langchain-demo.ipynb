{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-12-15T12:19:02.461339Z",
     "iopub.status.busy": "2024-12-15T12:19:02.461011Z",
     "iopub.status.idle": "2024-12-15T12:19:25.539143Z",
     "shell.execute_reply": "2024-12-15T12:19:25.538146Z",
     "shell.execute_reply.started": "2024-12-15T12:19:02.461302Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install langchain langchain_community\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:19:27.154556Z",
     "iopub.status.busy": "2024-12-15T12:19:27.154089Z",
     "iopub.status.idle": "2024-12-15T12:19:27.159508Z",
     "shell.execute_reply": "2024-12-15T12:19:27.158552Z",
     "shell.execute_reply.started": "2024-12-15T12:19:27.154512Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = \"xxxxxxxxxxxxxxxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:19:37.991326Z",
     "iopub.status.busy": "2024-12-15T12:19:37.990877Z",
     "iopub.status.idle": "2024-12-15T12:19:38.622897Z",
     "shell.execute_reply": "2024-12-15T12:19:38.622039Z",
     "shell.execute_reply.started": "2024-12-15T12:19:37.991295Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "\n",
    "llm = HuggingFaceHub(repo_id='google/flan-t5-large', model_kwargs={\"temperature\":0, \"max_length\":64})\n",
    "llm(\"translate to french: How old are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:20:16.691259Z",
     "iopub.status.busy": "2024-12-15T12:20:16.690329Z",
     "iopub.status.idle": "2024-12-15T12:20:17.181043Z",
     "shell.execute_reply": "2024-12-15T12:20:17.180275Z",
     "shell.execute_reply.started": "2024-12-15T12:20:16.691222Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "\n",
    "llm = HuggingFaceHub(repo_id='google/flan-t5-large', model_kwargs={\"temperature\":0, \"max_length\":100})\n",
    "name = llm.invoke(\"give 3 chinese food restaurant names\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:20:18.587346Z",
     "iopub.status.busy": "2024-12-15T12:20:18.586664Z",
     "iopub.status.idle": "2024-12-15T12:20:18.760113Z",
     "shell.execute_reply": "2024-12-15T12:20:18.759443Z",
     "shell.execute_reply.started": "2024-12-15T12:20:18.587314Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variable =['language'],\n",
    "    template=\"Translate 'How are you?' to {language}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:20:21.898909Z",
     "iopub.status.busy": "2024-12-15T12:20:21.898594Z",
     "iopub.status.idle": "2024-12-15T12:20:21.903571Z",
     "shell.execute_reply": "2024-12-15T12:20:21.902688Z",
     "shell.execute_reply.started": "2024-12-15T12:20:21.898877Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "p = prompt_template_name.format(language='French')\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:20:24.771018Z",
     "iopub.status.busy": "2024-12-15T12:20:24.770324Z",
     "iopub.status.idle": "2024-12-15T12:20:24.775088Z",
     "shell.execute_reply": "2024-12-15T12:20:24.774243Z",
     "shell.execute_reply.started": "2024-12-15T12:20:24.770982Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "p = prompt_template_name.format(language='German')\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:20:26.811868Z",
     "iopub.status.busy": "2024-12-15T12:20:26.811550Z",
     "iopub.status.idle": "2024-12-15T12:20:26.817748Z",
     "shell.execute_reply": "2024-12-15T12:20:26.816895Z",
     "shell.execute_reply.started": "2024-12-15T12:20:26.811843Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}\")\n",
    "prompt.format(product='socks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:20:51.642842Z",
     "iopub.status.busy": "2024-12-15T12:20:51.642466Z",
     "iopub.status.idle": "2024-12-15T12:20:51.676075Z",
     "shell.execute_reply": "2024-12-15T12:20:51.675436Z",
     "shell.execute_reply.started": "2024-12-15T12:20:51.642812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:20:52.299743Z",
     "iopub.status.busy": "2024-12-15T12:20:52.299443Z",
     "iopub.status.idle": "2024-12-15T12:20:52.361169Z",
     "shell.execute_reply": "2024-12-15T12:20:52.360354Z",
     "shell.execute_reply.started": "2024-12-15T12:20:52.299716Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "llm = HuggingFaceHub(repo_id='google/flan-t5-large', model_kwargs={\"temperature\": 0.5, \"max_length\": 100})\n",
    "prompt = PromptTemplate.from_template(\"translate to {language} : How are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:20:59.331663Z",
     "iopub.status.busy": "2024-12-15T12:20:59.331334Z",
     "iopub.status.idle": "2024-12-15T12:20:59.822911Z",
     "shell.execute_reply": "2024-12-15T12:20:59.821740Z",
     "shell.execute_reply.started": "2024-12-15T12:20:59.331631Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "print(chain.run({\"language\": \"132\"}))\n",
    "print(chain.run({\"language\": \"french\"}))\n",
    "print(chain.run({\"language\": \"german\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:21:15.018012Z",
     "iopub.status.busy": "2024-12-15T12:21:15.017028Z",
     "iopub.status.idle": "2024-12-15T12:21:15.094740Z",
     "shell.execute_reply": "2024-12-15T12:21:15.094107Z",
     "shell.execute_reply.started": "2024-12-15T12:21:15.017963Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "# Language model setup\n",
    "llm = HuggingFaceHub(repo_id='google/flan-t5-large', model_kwargs={\"temperature\": 0.5, \"max_length\": 100})\n",
    "\n",
    "# First chain: Suggest restaurant name\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.\"\n",
    ")\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "\n",
    "# Second chain: Suggest menu items\n",
    "promp_template_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template=\"Suggest some menu items for {restaurant_name}.\"\n",
    ")\n",
    "food_items_chain = LLMChain(llm=llm, prompt=promp_template_items)\n",
    "\n",
    "# Sequential chain combining both\n",
    "chain = SimpleSequentialChain(chains=[name_chain, food_items_chain])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:21:16.860690Z",
     "iopub.status.busy": "2024-12-15T12:21:16.860370Z",
     "iopub.status.idle": "2024-12-15T12:21:17.695553Z",
     "shell.execute_reply": "2024-12-15T12:21:17.694747Z",
     "shell.execute_reply.started": "2024-12-15T12:21:16.860663Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Run the chain\n",
    "content = chain.invoke(\"indian\")\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:21:20.958957Z",
     "iopub.status.busy": "2024-12-15T12:21:20.958628Z",
     "iopub.status.idle": "2024-12-15T12:21:20.963423Z",
     "shell.execute_reply": "2024-12-15T12:21:20.962533Z",
     "shell.execute_reply.started": "2024-12-15T12:21:20.958927Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# First chain: Suggest restaurant name\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=['cuisine'],\n",
    "    template=\"I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.\"\n",
    ")\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name, output_key='restaurant_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:21:23.245857Z",
     "iopub.status.busy": "2024-12-15T12:21:23.245538Z",
     "iopub.status.idle": "2024-12-15T12:21:23.250215Z",
     "shell.execute_reply": "2024-12-15T12:21:23.249374Z",
     "shell.execute_reply.started": "2024-12-15T12:21:23.245829Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "promp_template_items = PromptTemplate(\n",
    "    input_variables=['restaurant_name'],\n",
    "    template=\"Suggest some menu items for {restaurant_name}.\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm=llm, prompt=promp_template_items, output_key='menu_items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T12:21:50.663061Z",
     "iopub.status.busy": "2024-12-15T12:21:50.662360Z",
     "iopub.status.idle": "2024-12-15T12:21:56.518136Z",
     "shell.execute_reply": "2024-12-15T12:21:56.517335Z",
     "shell.execute_reply.started": "2024-12-15T12:21:50.663025Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains = [name_chain, food_items_chain],\n",
    "    input_variables = ['cuisine'],\n",
    "    output_variables =['restaurant_name', 'menu_items'])\n",
    "\n",
    "print(chain.invoke({'cuisine':'xander'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents And Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
