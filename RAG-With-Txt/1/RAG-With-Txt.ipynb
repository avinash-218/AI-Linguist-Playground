{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-12-26T17:47:14.606136Z",
     "iopub.status.busy": "2024-12-26T17:47:14.605883Z",
     "iopub.status.idle": "2024-12-26T17:47:15.679714Z",
     "shell.execute_reply": "2024-12-26T17:47:15.678774Z",
     "shell.execute_reply.started": "2024-12-26T17:47:14.606102Z"
    },
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1735237294332,
     "user": {
      "displayName": "Avinash",
      "userId": "17332923784379016752"
     },
     "user_tz": -330
    },
    "id": "aYLprF7jFesC",
    "outputId": "156bff5d-1996-49a8-b572-c08590934eae",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 26 18:21:33 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   72C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-26T17:47:23.790884Z",
     "iopub.status.busy": "2024-12-26T17:47:23.790595Z"
    },
    "executionInfo": {
     "elapsed": 8829,
     "status": "ok",
     "timestamp": 1735237306008,
     "user": {
      "displayName": "Avinash",
      "userId": "17332923784379016752"
     },
     "user_tz": -330
    },
    "id": "tVQui1ejFesH",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip -q install sentence_transformers langchain tiktoken chromadb pypdf transformers langchain_community\n",
    "!pip -q install accelerate bitsandbytes sentencepiece Xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 14168,
     "status": "ok",
     "timestamp": 1735237336989,
     "user": {
      "displayName": "Avinash",
      "userId": "17332923784379016752"
     },
     "user_tz": -330
    },
    "id": "Jcjj7wkwFesJ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44548,
     "status": "ok",
     "timestamp": 1735237381535,
     "user": {
      "displayName": "Avinash",
      "userId": "17332923784379016752"
     },
     "user_tz": -330
    },
    "id": "FFajSG6cFesJ",
    "outputId": "13145bfd-9f26-4c50-ef10-ab7823a0ad5a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-26 18:22:16--  https://github.com/Shafi2016/Youtube/raw/main/stock_market_june_2023.zip\n",
      "Resolving github.com (github.com)... 20.27.177.113\n",
      "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/Shafi2016/Youtube/main/stock_market_june_2023.zip [following]\n",
      "--2024-12-26 18:22:16--  https://raw.githubusercontent.com/Shafi2016/Youtube/main/stock_market_june_2023.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10638 (10K) [application/zip]\n",
      "Saving to: ‘stock_market_june_2023.zip’\n",
      "\n",
      "stock_market_june_2 100%[===================>]  10.39K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2024-12-26 18:22:17 (7.44 MB/s) - ‘stock_market_june_2023.zip’ saved [10638/10638]\n",
      "\n",
      "Archive:  stock_market_june_2023.zip\n",
      "replace stock_market_june_2023/Arbor Metals Corp.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
      "replace stock_market_june_2023/Intuitive Surgical.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/Shafi2016/Youtube/raw/main/stock_market_june_2023.zip -O stock_market_june_2023.zip\n",
    "!unzip stock_market_june_2023.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 930,
     "status": "ok",
     "timestamp": 1735237387984,
     "user": {
      "displayName": "Avinash",
      "userId": "17332923784379016752"
     },
     "user_tz": -330
    },
    "id": "39vfjmkVFesK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('/content/stock_market_june_2023', glob='./*.txt', loader_cls=TextLoader)\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1735237388678,
     "user": {
      "displayName": "Avinash",
      "userId": "17332923784379016752"
     },
     "user_tz": -330
    },
    "id": "Stns_vCEFesK",
    "outputId": "834dbb50-ff47-4e36-b305-cefb8084d77c",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#documents\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 627,
     "status": "ok",
     "timestamp": 1735237391566,
     "user": {
      "displayName": "Avinash",
      "userId": "17332923784379016752"
     },
     "user_tz": -330
    },
    "id": "ts3BbjgeFesL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1735237391566,
     "user": {
      "displayName": "Avinash",
      "userId": "17332923784379016752"
     },
     "user_tz": -330
    },
    "id": "NLsUS5GRFesL",
    "outputId": "54150b1f-3889-48b9-f3c3-3e7222b1507e",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)\n",
    "#texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225,
     "referenced_widgets": [
      "b478b17fec734f39b8d9e849d3b2d5dd",
      "19367fc87dc04dd2acc314f0f6c235b0",
      "2e7f15d5b7f84334be7a5a3eae8df92e",
      "057e5ade66bd4961bf73f5f9f5c5ba68",
      "15f3a6b84e7a4438bc91ce45c38750df",
      "9f7840d1d9f64735ba31636af5df5516",
      "69dc5004f6854d8989ee9fcdf120010e",
      "17efa682f75f4b1bb8deffc1d1010d02",
      "82f6726adcfe4189a13844ad7baa7191",
      "8e45e1142969475cac8e22aecfe192b1",
      "7ceab02a9f8040458444b6a4f3188bd1"
     ]
    },
    "executionInfo": {
     "elapsed": 60921,
     "status": "ok",
     "timestamp": 1735237456544,
     "user": {
      "displayName": "Avinash",
      "userId": "17332923784379016752"
     },
     "user_tz": -330
    },
    "id": "pS3XX6BRFesM",
    "outputId": "37021dd0-c4fd-4b03-f73a-c05e58c9f6a7",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "WARNING:transformers_modules.tiiuae.falcon-7b-instruct.8782b5c5d8c9290412416618f36a133653e85285.configuration_falcon:\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b478b17fec734f39b8d9e849d3b2d5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = 'tiiuae/falcon-7b-instruct'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    'text-generation',\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=300,  # Set max tokens for the output\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map='cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 806,
     "status": "ok",
     "timestamp": 1735237526768,
     "user": {
      "displayName": "Avinash",
      "userId": "17332923784379016752"
     },
     "user_tz": -330
    },
    "id": "KkSSxm0TFesN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9869,
     "status": "ok",
     "timestamp": 1735237538858,
     "user": {
      "displayName": "Avinash",
      "userId": "17332923784379016752"
     },
     "user_tz": -330
    },
    "id": "q1Kbuzq9G5zh",
    "outputId": "7cfbc896-7dc2-4e9a-910d-d524e7775c2a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-dfd8260087bf>:1: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=pipeline)\n",
      "<ipython-input-11-dfd8260087bf>:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  hf = HuggingFaceEmbeddings(model_name=model_name)\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFacePipeline(pipeline=pipeline)\n",
    "\n",
    "model_name = 'intfloat/e5-large-v2'\n",
    "hf = HuggingFaceEmbeddings(model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KN8-VEpsHZ5_"
   },
   "source": [
    "# Create DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 3263,
     "status": "ok",
     "timestamp": 1735237543648,
     "user": {
      "displayName": "Avinash",
      "userId": "17332923784379016752"
     },
     "user_tz": -330
    },
    "id": "UX6O807KHYjI"
   },
   "outputs": [],
   "source": [
    "persist_directory = 'db'  #directory where embeddings will be stored\n",
    "\n",
    "# convert documents to embeddings using hugging face embedding and then specifies the path where the vector database of those embeddings are to be stored\n",
    "vectordb = Chroma.from_documents(documents=texts,\n",
    "                                 embedding=hf,\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 643,
     "status": "ok",
     "timestamp": 1735237584489,
     "user": {
      "displayName": "Avinash",
      "userId": "17332923784379016752"
     },
     "user_tz": -330
    },
    "id": "IN-FcSL9Hosh",
    "outputId": "5c995ca0-80cf-4805-d055-a5a991f201ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-fb36a474b514>:1: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()  #persists the embedding database to disk\n",
      "<ipython-input-13-fb36a474b514>:3: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(persist_directory=persist_directory,  # load the stored vector embeddings to chroma db\n"
     ]
    }
   ],
   "source": [
    "vectordb.persist()  #persists the embedding database to disk\n",
    "\n",
    "vectordb = Chroma(persist_directory=persist_directory,  # load the stored vector embeddings to chroma db\n",
    "                  embedding_function=hf)  # use embedding function to query and search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1735237587764,
     "user": {
      "displayName": "Avinash",
      "userId": "17332923784379016752"
     },
     "user_tz": -330
    },
    "id": "yYqp4j0LJHvR"
   },
   "outputs": [],
   "source": [
    "# init retriever object with 3 search results\n",
    "retriever = vectordb.as_retriever(search_kwargs={'k':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1735237589204,
     "user": {
      "displayName": "Avinash",
      "userId": "17332923784379016752"
     },
     "user_tz": -330
    },
    "id": "mxrZqVX5JXjm"
   },
   "outputs": [],
   "source": [
    "# initialize Q & A langchain's chain\n",
    "# user query is used to retrieve the most relevant 3 documents from the db\n",
    "# all of the 3 relevant documents are concatenated (stuff)\n",
    "# then it is passed to the llm along with the user query\n",
    "# llm return the answer\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                                       chain_type='stuff',\n",
    "                                       retriever=retriever,\n",
    "                                       return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 718,
     "status": "ok",
     "timestamp": 1735237590658,
     "user": {
      "displayName": "Avinash",
      "userId": "17332923784379016752"
     },
     "user_tz": -330
    },
    "id": "1Dm4rUboKUZZ"
   },
   "outputs": [],
   "source": [
    "def process_llm_response(llm_response):\n",
    "  print(llm_response['result'])\n",
    "\n",
    "  for source in llm_response['source_documents']:\n",
    "    print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9734,
     "status": "ok",
     "timestamp": 1735237636956,
     "user": {
      "displayName": "Avinash",
      "userId": "17332923784379016752"
     },
     "user_tz": -330
    },
    "id": "1I3AtuBhKjJn",
    "outputId": "c94e897b-92fe-4fde-e4b9-18ae19adb721"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "To adapt to the changing landscape, Shopify implemented significant changes, including workforce layoffs of approximately 20% and selling its logistics business to Flexport. Although these changes incur near-term expenses, such as restructuring and impairment charges, they will ultimately reduce overhead costs and make Shopify more asset-light in the long run.\n",
      "\n",
      "To adapt to the changing landscape, Shopify implemented significant changes, including workforce layoffs of approximately 20% and selling its logistics business to Flexport. Although these changes incur near-term expenses, such as restructuring and impairment charges, they will ultimately reduce overhead costs and make Shopify more asset-light in the long run.\n",
      "\n",
      "To adapt to the changing landscape, Shopify implemented significant changes, including workforce layoffs of approximately 20% and selling its logistics business to Flexport. Although these changes incur near-term expenses, such as restructuring and impairment charges, they will ultimately reduce overhead costs and make Shopify more asset-light in the long run.\n",
      "\n",
      "Question: What were the reasons behind Shopify's decision to lay off a portion of its workforce?\n",
      "Helpful Answer:\n",
      "The decision to lay off a portion of Shopify's workforce was made to reduce overall costs and streamline the company's operations. The company expects that this move will result in near-term expenses, such as restructuring and impairment charges, but will ultimately reduce overhead costs and make Shopify more asset-light in the long run.\n",
      "/content/stock_market_june_2023/Shopify.txt\n",
      "/content/stock_market_june_2023/Shopify.txt\n",
      "/content/stock_market_june_2023/Shopify.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"What were the reasons behind Shopify's decision to lay off a portion of its workforce?\"\n",
    "response = qa_chain(query)\n",
    "process_llm_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5324,
     "status": "ok",
     "timestamp": 1735237701370,
     "user": {
      "displayName": "Avinash",
      "userId": "17332923784379016752"
     },
     "user_tz": -330
    },
    "id": "rOxf-Z-rOOUo",
    "outputId": "a0ec6098-03fd-42fc-b0d8-58e02e1f4d43"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Nvidia’s shares have seen a massive surge since the beginning of 2023, indicating that the market recognizes the company’s substantial potential in the AI industry. While some may consider the stock to be pricy, Nvidia has a lot of things going for it to help justify the premium price tag.\n",
      "\n",
      "Nvidia’s shares have seen a massive surge since the beginning of 2023, indicating that the market recognizes the company’s substantial potential in the AI industry. While some may consider the stock to be pricy, Nvidia has a lot of things going for it to help justify the premium price tag.\n",
      "\n",
      "Nvidia’s shares have seen a massive surge since the beginning of 2023, indicating that the market recognizes the company’s substantial potential in the AI industry. While some may consider the stock to be pricy, Nvidia has a lot of things going for it to help justify the premium price tag.\n",
      "\n",
      "Question: What were the reason behind Nvidia's stock growth?\n",
      "Helpful Answer:\n",
      "Nvidia's stock has seen a surge in 2023 due to the company's substantial potential in the AI industry, which has been recognized by the market.\n",
      "/content/stock_market_june_2023/NVIDIA Corporation.txt\n",
      "/content/stock_market_june_2023/NVIDIA Corporation.txt\n",
      "/content/stock_market_june_2023/NVIDIA Corporation.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"What were the reason behind Nvidia's stock growth?\"\n",
    "response = qa_chain(query)\n",
    "process_llm_response(response)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "057e5ade66bd4961bf73f5f9f5c5ba68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e45e1142969475cac8e22aecfe192b1",
      "placeholder": "​",
      "style": "IPY_MODEL_7ceab02a9f8040458444b6a4f3188bd1",
      "value": " 2/2 [00:57&lt;00:00, 26.74s/it]"
     }
    },
    "15f3a6b84e7a4438bc91ce45c38750df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17efa682f75f4b1bb8deffc1d1010d02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "19367fc87dc04dd2acc314f0f6c235b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f7840d1d9f64735ba31636af5df5516",
      "placeholder": "​",
      "style": "IPY_MODEL_69dc5004f6854d8989ee9fcdf120010e",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "2e7f15d5b7f84334be7a5a3eae8df92e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_17efa682f75f4b1bb8deffc1d1010d02",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_82f6726adcfe4189a13844ad7baa7191",
      "value": 2
     }
    },
    "69dc5004f6854d8989ee9fcdf120010e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7ceab02a9f8040458444b6a4f3188bd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "82f6726adcfe4189a13844ad7baa7191": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8e45e1142969475cac8e22aecfe192b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f7840d1d9f64735ba31636af5df5516": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b478b17fec734f39b8d9e849d3b2d5dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_19367fc87dc04dd2acc314f0f6c235b0",
       "IPY_MODEL_2e7f15d5b7f84334be7a5a3eae8df92e",
       "IPY_MODEL_057e5ade66bd4961bf73f5f9f5c5ba68"
      ],
      "layout": "IPY_MODEL_15f3a6b84e7a4438bc91ce45c38750df"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
